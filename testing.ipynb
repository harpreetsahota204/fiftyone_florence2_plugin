{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing implemention of Florence2 as FO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install einops timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fiftyone/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from florence2 import Florence2, run_florence2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded\n",
      "Loading existing dataset 'quickstart'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\"quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH =\"microsoft/Florence-2-base-ft\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Captioning\n",
    "\n",
    "```python\n",
    "\n",
    "    \"caption\": {\n",
    "        \"params\": {\"detail_level\": [\"basic\", \"detailed\", \"more_detailed\"]},\n",
    "        \"required\": [],\n",
    "        \"task_mapping\": {\n",
    "            \"detailed\": \"<DETAILED_CAPTION>\",\n",
    "            \"more_detailed\": \"<MORE_DETAILED_CAPTION>\",\n",
    "            \"basic\": \"<CAPTION>\",\n",
    "            None: \"<CAPTION>\"  # Default value\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fiftyone/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [59.0s elapsed, 0s remaining, 3.5 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "run_florence2_model(\n",
    "    dataset,\n",
    "    model_path=MODEL_PATH,\n",
    "    operation=\"caption\",\n",
    "    detail_level=\"basic\",\n",
    "    output_field=\"basic_caption\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [2.4m elapsed, 0s remaining, 1.4 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "run_florence2_model(\n",
    "    dataset,\n",
    "    model_path=MODEL_PATH,\n",
    "    operation=\"caption\",\n",
    "    detail_level=\"detailed\",\n",
    "    output_field=\"detailed_caption\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [3.1m elapsed, 0s remaining, 1.4 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "run_florence2_model(\n",
    "    dataset,\n",
    "    model_path=MODEL_PATH,\n",
    "    operation=\"caption\",\n",
    "    detail_level=\"more_detailed\",\n",
    "    output_field=\"more_detailed_caption\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sample: {\n",
       "    'id': '67dda8b4de3b57ba0da3dc35',\n",
       "    'media_type': 'image',\n",
       "    'filepath': '/Users/harpreetsahota/fiftyone/quickstart/data/000880.jpg',\n",
       "    'tags': ['validation'],\n",
       "    'metadata': None,\n",
       "    'created_at': datetime.datetime(2025, 3, 21, 17, 58, 12, 429000),\n",
       "    'last_modified_at': datetime.datetime(2025, 3, 21, 20, 20, 5, 540000),\n",
       "    'ground_truth': <Detections: {\n",
       "        'detections': [\n",
       "            <Detection: {\n",
       "                'id': '5f452471ef00e6374aac53c8',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'bird',\n",
       "                'bounding_box': [0.21084375, 0.0034375, 0.46190625, 0.9442083333333334],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': None,\n",
       "                'index': None,\n",
       "                'area': 73790.37944999996,\n",
       "                'iscrowd': 0.0,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452471ef00e6374aac53c9',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'bird',\n",
       "                'bounding_box': [0.74946875, 0.489375, 0.2164375, 0.23183333333333334],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': None,\n",
       "                'index': None,\n",
       "                'area': 3935.7593000000006,\n",
       "                'iscrowd': 0.0,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452471ef00e6374aac53ca',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'bird',\n",
       "                'bounding_box': [\n",
       "                    0.044234375,\n",
       "                    0.5282083333333333,\n",
       "                    0.151390625,\n",
       "                    0.14145833333333335,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': None,\n",
       "                'index': None,\n",
       "                'area': 4827.32605,\n",
       "                'iscrowd': 0.0,\n",
       "            }>,\n",
       "        ],\n",
       "    }>,\n",
       "    'uniqueness': 0.8175834390151201,\n",
       "    'predictions': <Detections: {\n",
       "        'detections': [\n",
       "            <Detection: {\n",
       "                'id': '5f452c60ef00e6374aad9394',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'bird',\n",
       "                'bounding_box': [\n",
       "                    0.22192673683166503,\n",
       "                    0.06093006531397502,\n",
       "                    0.4808845520019531,\n",
       "                    0.8937615712483724,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': 0.9750854969024658,\n",
       "                'index': None,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452c60ef00e6374aad9395',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'bird',\n",
       "                'bounding_box': [\n",
       "                    0.3962469816207886,\n",
       "                    0.006943931678930918,\n",
       "                    0.27418792247772217,\n",
       "                    0.46793556213378906,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': 0.759726881980896,\n",
       "                'index': None,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452c60ef00e6374aad9396',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'bird',\n",
       "                'bounding_box': [\n",
       "                    0.02506386339664459,\n",
       "                    0.548487663269043,\n",
       "                    0.16438478231430054,\n",
       "                    0.16736234029134114,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': 0.6569182276725769,\n",
       "                'index': None,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452c60ef00e6374aad9397',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'bird',\n",
       "                'bounding_box': [\n",
       "                    0.4889101028442383,\n",
       "                    0.009576511383056641,\n",
       "                    0.13802199363708495,\n",
       "                    0.2093157132466634,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': 0.2359301745891571,\n",
       "                'index': None,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452c60ef00e6374aad9398',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'elephant',\n",
       "                'bounding_box': [\n",
       "                    0.015171945095062256,\n",
       "                    0.555288823445638,\n",
       "                    0.1813342332839966,\n",
       "                    0.15938574473063152,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': 0.221974179148674,\n",
       "                'index': None,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452c60ef00e6374aad9399',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'bear',\n",
       "                'bounding_box': [\n",
       "                    0.017808181047439576,\n",
       "                    0.5488224665323893,\n",
       "                    0.17450940608978271,\n",
       "                    0.16891117095947267,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': 0.1965726613998413,\n",
       "                'index': None,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452c60ef00e6374aad939a',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'elephant',\n",
       "                'bounding_box': [\n",
       "                    0.16558188199996948,\n",
       "                    0.5723957061767578,\n",
       "                    0.09993256330490112,\n",
       "                    0.10098978678385416,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': 0.18904592096805573,\n",
       "                'index': None,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452c60ef00e6374aad939b',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'sheep',\n",
       "                'bounding_box': [\n",
       "                    0.213010573387146,\n",
       "                    0.05354320605595907,\n",
       "                    0.5153374671936035,\n",
       "                    0.8933518091837566,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': 0.11480894684791565,\n",
       "                'index': None,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452c60ef00e6374aad939c',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'bird',\n",
       "                'bounding_box': [\n",
       "                    0.29751906394958494,\n",
       "                    0.010790024201075237,\n",
       "                    0.3315577507019043,\n",
       "                    0.34026527404785156,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': 0.11089690029621124,\n",
       "                'index': None,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452c60ef00e6374aad939d',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'elephant',\n",
       "                'bounding_box': [\n",
       "                    0.08351035118103027,\n",
       "                    0.5574632008870443,\n",
       "                    0.18209288120269776,\n",
       "                    0.1426785151163737,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': 0.0971052274107933,\n",
       "                'index': None,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452c60ef00e6374aad939e',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'bird',\n",
       "                'bounding_box': [\n",
       "                    0.4461814880371094,\n",
       "                    0.0007838249827424685,\n",
       "                    0.209574556350708,\n",
       "                    0.309667714436849,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': 0.08403241634368896,\n",
       "                'index': None,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452c60ef00e6374aad939f',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'bird',\n",
       "                'bounding_box': [\n",
       "                    0.5395165920257569,\n",
       "                    0.034476550420125325,\n",
       "                    0.07703280448913574,\n",
       "                    0.16296254793802897,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': 0.07699568569660187,\n",
       "                'index': None,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452c60ef00e6374aad93a0',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'bear',\n",
       "                'bounding_box': [\n",
       "                    0.217216157913208,\n",
       "                    0.05954849322636922,\n",
       "                    0.49451656341552735,\n",
       "                    0.8721434275309244,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': 0.058097004890441895,\n",
       "                'index': None,\n",
       "            }>,\n",
       "            <Detection: {\n",
       "                'id': '5f452c60ef00e6374aad93a1',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'sheep',\n",
       "                'bounding_box': [\n",
       "                    0.018094074726104737,\n",
       "                    0.5562847137451172,\n",
       "                    0.17362892627716064,\n",
       "                    0.15742950439453124,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': 0.0519101656973362,\n",
       "                'index': None,\n",
       "            }>,\n",
       "        ],\n",
       "    }>,\n",
       "    'florence_caption': 'A rooster standing in the middle of a field.',\n",
       "    'basic_caption': 'A rooster standing in the middle of a field.',\n",
       "    'florence_phrase_grounding': <Detections: {\n",
       "        'detections': [\n",
       "            <Detection: {\n",
       "                'id': '67ddc8d869369e05cd357bee',\n",
       "                'attributes': {},\n",
       "                'tags': [],\n",
       "                'label': 'A rooster',\n",
       "                'bounding_box': [\n",
       "                    0.2254999876022339,\n",
       "                    0.0004999999888241291,\n",
       "                    0.4450000047683716,\n",
       "                    0.9249999796661238,\n",
       "                ],\n",
       "                'mask': None,\n",
       "                'mask_path': None,\n",
       "                'confidence': None,\n",
       "                'index': None,\n",
       "            }>,\n",
       "        ],\n",
       "    }>,\n",
       "    'detailed_caption': 'In this image we can see hens on the ground. In the background there are trees and sky.',\n",
       "    'more_detailed_caption': 'A black and white hen is standing in a field. There are weeds and grass around the hen. There is a small white bird next to it. ',\n",
       "}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phrase grounding\n",
    "\n",
    "\n",
    "```python\n",
    "    \"phrase_grounding\": {\n",
    "        \"params\": {\"caption_field\": str, \"caption\": str},\n",
    "        \"required\": [],  # Will be validated in code\n",
    "        \"task\": \"<CAPTION_TO_PHRASE_GROUNDING>\"\n",
    "    },\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "run_florence2_model(\n",
    "    dataset,\n",
    "    model_path=MODEL_PATH,\n",
    "    operation=\"phrase_grounding\",\n",
    "    caption_field=\"detailed_caption\",\n",
    "    output_field=\"florence_phrase_grounding\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_florence2_model(\n",
    "    dataset,\n",
    "    operation=\"phrase_grounding\",\n",
    "    model_path=MODEL_PATH,\n",
    "    caption=\"The inanimate object\",\n",
    "    output_field=\"fake_caption_phrase_grounding\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detection\n",
    "\n",
    "```python\n",
    "\"detection\": {\n",
    "        \"params\": {\"detection_type\": [\"detection\", \"dense_region_caption\", \"region_proposal\", \"open_vocabulary_detection\"],\n",
    "                   \"text_prompt\": str},\n",
    "        \"required\": [],\n",
    "        \"task_mapping\": {\n",
    "            \"detection\": \"<OD>\",\n",
    "            \"dense_region_caption\": \"<DENSE_REGION_CAPTION>\",\n",
    "            \"region_proposal\": \"<REGION_PROPOSAL>\",\n",
    "            \"open_vocabulary_detection\": \"<OPEN_VOCABULARY_DETECTION>\",\n",
    "            None: \"<OD>\"  # Default value\n",
    "        }\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_florence2_model(\n",
    "    dataset,\n",
    "    operation=\"detection\",\n",
    "    detection_type=\"detection\"\n",
    "    model_path=MODEL_PATH,\n",
    "    # output_field=\"florence_phrase_grounding\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_florence2_model(\n",
    "    dataset,\n",
    "    operation=\"detection\",\n",
    "    detection_type=\"dense_region_caption\"\n",
    "    model_path=MODEL_PATH,\n",
    "    # output_field=\"florence_phrase_grounding\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_florence2_model(\n",
    "    dataset,\n",
    "    operation=\"detection\",\n",
    "    detection_type=\"region_proposal\"\n",
    "    model_path=MODEL_PATH,\n",
    "    # output_field=\"florence_phrase_grounding\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_florence2_model(\n",
    "    dataset,\n",
    "    operation=\"detection\",\n",
    "    detection_type=\"open_vocabulary_detection\"\n",
    "    model_path=MODEL_PATH,\n",
    "    # output_field=\"florence_phrase_grounding\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Segmentation\n",
    "\n",
    "```python\n",
    "\n",
    "    \"segmentation\": {\n",
    "        \"params\": {\"expression\": str, \"expression_field\": str},\n",
    "        \"required\": [],  # Will be validated in code\n",
    "        \"task\": \"<REFERRING_EXPRESSION_SEGMENTATION>\"\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_florence2_model(\n",
    "    dataset,\n",
    "    operation=\"segmentation\",\n",
    "    expression=\"\"\n",
    "    model_path=MODEL_PATH,\n",
    "    # output_field=\"florence_phrase_grounding\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_florence2_model(\n",
    "    dataset,\n",
    "    operation=\"segmentation\",\n",
    "    expression_field=\"\"\n",
    "    model_path=MODEL_PATH,\n",
    "    # output_field=\"florence_phrase_grounding\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ocr\n",
    "\n",
    "```python\n",
    "    \"ocr\": {\n",
    "        \"params\": {\"store_region_info\": bool},\n",
    "        \"required\": [],\n",
    "        \"task\": \"<OCR>\",\n",
    "        \"region_task\": \"<OCR_WITH_REGION>\"\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_florence2_model(\n",
    "    dataset,\n",
    "    model_path=MODEL_PATH,\n",
    "    store_region_info=True\n",
    "    # output_field=\"florence_phrase_grounding\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_florence2_model(\n",
    "    dataset,\n",
    "    model_path=MODEL_PATH,\n",
    "    store_region_info=False\n",
    "    # output_field=\"florence_phrase_grounding\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
